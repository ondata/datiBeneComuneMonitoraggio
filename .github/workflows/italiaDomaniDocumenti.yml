name: italiaDomani Documenti

on:
#  push:
  repository_dispatch:
  schedule:
    - cron:  '15 9,17 */1 * *'
  workflow_dispatch:

jobs:
  scheduled:
    runs-on: ubuntu-latest
    steps:
    - name: Utilizza l'action github checkout@v2, per automatizzare il check-out
      uses: actions/checkout@v2
      with:
        fetch-depth: 0
    - name: Installa Google Chrome (per scraping headless)
      run: |-
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" > /etc/apt/sources.list.d/google-chrome.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
    - name: crea cartella utente bin, copia dentro l'eseguibile di scrape, installa yq e miller e gdal
      run: |-
        sudo apt-get install miller
        mkdir -p ~/bin
        cp bin/scrape ~/bin
        cd ~/bin
        chmod +x scrape
        sudo pip install yq
        sudo apt-get install gdal-bin
    - name: scarica i dati
      run: |-
        export PATH=$PATH:~/bin
        cd ./catalogo/italiaDomaniDocumenti/script
        chmod +x ./italiaDomaniDocumenti.sh
        ./italiaDomaniDocumenti.sh
    - name: Committa e pusha se ci sono variazioni nei dati
      run: |-
        git config user.name "automatico"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date --iso-8601=seconds)
        git commit -m "italiaDomani Documenti: ${timestamp}" || exit 0
        git push

